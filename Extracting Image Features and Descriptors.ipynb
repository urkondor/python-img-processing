{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Extracting Image Features and Descriptors\n",
    "\n",
    "Finally. We made it to the really cool stuff. We're going to talk about feature detectors & descriptors, look at the types that are out there, and pat ourselves on the back a little bit that we have a basic understanding of image processing, and know what goes into the deep learning algorithms. Specifically, we'll cover:<ul><li>detectors vs. descriptors, & extraction</li><li>harris corner detector</li><li>blob detectors with LoG, DoG, and DoH</li><li>HOG! HOG! HOG! HOG!</li><li>SIFT, ORB, and BRIEF features and their application in image matching</li><li>Haar-like features and their application in face detection</li></ul>\n",
    "\n",
    "Welcome to the party.\n",
    "\n",
    "## Detectors vs. Descriptors\n",
    "\n",
    "<strong>Detectors</strong> are a family of algorithms that choose a set of interest ponts based on corners, local max/min, etc.. On the other hand, <strong>descriptors</strong> represnets the image with those characteristics, transforming the image into a set of descriptors, performing a sort of dimensionality reduction. A <em>feature</em>, then, is formed by an interest point and its descriptor together.\n",
    "\n",
    "To implement these, we'll be using `python-opencv` like the big kids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab as pylab\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
    "from skimage.transform import warp, SimilarityTransform, AffineTransform, resize\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage.util import img_as_float\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.measure import ransac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Harris Corner Detector\n",
    "\n",
    "This fella explores intensity changes within a window (kernel). While edges represent pixels whose values change abruptly in one direction, corners represent points where the values change abruptly in all directions. So as the kernel traverses the array (we can just call it that by now, right?), the intensity value should change drastically. That is what the Harris Corner Detector looks out for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (4,) could not be broadcast to indexing result of shape (12840,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-86fae1d6ed4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorner_harris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoords\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (4,) could not be broadcast to indexing result of shape (12840,3)"
     ]
    }
   ],
   "source": [
    "img = imread('./img/jellyfish_crop.jpg')\n",
    "img_gray = rgb2gray(img)\n",
    "coords = corner_harris(img_gray, k=0.001)\n",
    "img[coords > 0.01 * coords.max()] = [255, 0, 0, 255]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob Detectors with LoG, DoG, and DoH\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
